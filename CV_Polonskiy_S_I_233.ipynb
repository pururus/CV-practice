{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pVBiGhMfc6ws"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from tqdm import tqdm_notebook\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import torch, torchvision\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(69)"
      ],
      "metadata": {
        "id": "kwBf3BRwdYwH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = datasets.CIFAR10(root='./data', train=True, download=True, transform=transforms.ToTensor())\n",
        "train_data, valid_data = train_test_split(train_data, test_size=0.1)\n",
        "test_data = datasets.CIFAR10(root='./data', train=False, download=True, transform=transforms.ToTensor())"
      ],
      "metadata": {
        "id": "sP7jNecmdZnt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=8, shuffle=True)\n",
        "valid_loader = torch.utils.data.DataLoader(valid_data, batch_size=8, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size=8, shuffle=True)"
      ],
      "metadata": {
        "id": "N7yfj5kadbn3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataiter = iter(train_loader)\n",
        "test_dataiter = iter(test_loader)\n"
      ],
      "metadata": {
        "id": "CqIjW3k6dfBD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imgs, labels = next(train_dataiter)"
      ],
      "metadata": {
        "id": "5Q0EMhZOdhRW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_to_name = {\n",
        "    0: \"Самолет\",\n",
        "    1: \"Авто\",\n",
        "    2: \"Птица\",\n",
        "    3: \"Кот\",\n",
        "    4: \"Олень\",\n",
        "    5: \"Собака\",\n",
        "    6: \"Лягушка\",\n",
        "    7: \"Лошадь\",\n",
        "    8: \"Корабль\",\n",
        "    9: \"Грузовик\"\n",
        "}"
      ],
      "metadata": {
        "id": "BYTFR3tEdh_f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def show(imgs, labels):\n",
        "  f, axes = plt.subplots(1, 8, figsize=(30, 30))\n",
        "  for i, axis in enumerate(axes):\n",
        "    axes[i].imshow(np.squeeze(np.transpose(imgs[i].numpy(), (1, 2, 0))), cmap='gray')\n",
        "    axes[i].set_title(label_to_name[int(labels[i].numpy())])\n",
        "  plt.show()\n"
      ],
      "metadata": {
        "id": "cfnHLkqRdmDX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show(imgs, labels)"
      ],
      "metadata": {
        "id": "qjD-OKlidm5a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "1ZUIuIFudpV3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "device"
      ],
      "metadata": {
        "id": "sdS_sJnTdsT7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ToVect(nn.Module):\n",
        "  def forward(self, img):\n",
        "    return img.view(img.size(0), -1)"
      ],
      "metadata": {
        "id": "efvzB7qNdv_i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Рассмотрим несколько вариантов упрощенной архитектуры перед тем, как усложнить и доучить ее"
      ],
      "metadata": {
        "id": "v9IS8mt6kvWI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ks = 3\n",
        "cc = 2\n",
        "\n",
        "class CNN(nn.Module): #один пулинг\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(CNN, self).__init__()\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Conv2d(3, 20, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(20),\n",
        "            nn.ReLU())\n",
        "        self.layer2 = nn.Sequential(\n",
        "            nn.Conv2d(20, 20, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(20),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
        "        self.layer3 = nn.Sequential(\n",
        "            nn.Conv2d(20, 40, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(40),\n",
        "            nn.ReLU())\n",
        "        self.layer4 = nn.Sequential(\n",
        "            nn.Conv2d(40, 40, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(40),\n",
        "            nn.ReLU(),\n",
        "            # nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
        "            )\n",
        "        self.layer5 = nn.Sequential(\n",
        "            nn.Conv2d(40, 40, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(40),\n",
        "            nn.ReLU())\n",
        "        self.layer6 = nn.Sequential(\n",
        "            nn.Conv2d(40, 40, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(40),\n",
        "            nn.ReLU())\n",
        "        self.layer7 = nn.Sequential(\n",
        "            nn.Sequential(\n",
        "            nn.Conv2d(40, 40, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(40),\n",
        "            nn.ReLU()),\n",
        "\n",
        "            nn.Sequential(\n",
        "            nn.Conv2d(40, 40, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(40),\n",
        "            nn.ReLU()),\n",
        "\n",
        "            # nn.Sequential(\n",
        "            # nn.Conv2d(40, 40, kernel_size=3, stride=1, padding=1),\n",
        "            # nn.BatchNorm2d(40),\n",
        "            # nn.ReLU())\n",
        "        )\n",
        "        self.tovect = ToVect()\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(10240, 1000),\n",
        "            nn.ReLU())\n",
        "        self.fc1 = nn.Sequential(\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(1000, 100),\n",
        "            nn.ReLU())\n",
        "        self.fc2= nn.Sequential(\n",
        "            nn.Linear(100, num_classes))\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.layer1(x).to(device)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "        out = self.layer5(out)\n",
        "        out = self.layer6(out)\n",
        "        out = self.layer7(out)\n",
        "        out = self.tovect(out)\n",
        "        out = self.fc(out)\n",
        "        out = self.fc1(out)\n",
        "        out = self.fc2(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "AEndyXgHdxC5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ks = 3\n",
        "cc = 2\n",
        "\n",
        "class CNN2(nn.Module): #два пулинга\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(CNN2, self).__init__()\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Conv2d(3, 20, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(20),\n",
        "            nn.ReLU())\n",
        "        self.layer2 = nn.Sequential(\n",
        "            nn.Conv2d(20, 20, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(20),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
        "        self.layer3 = nn.Sequential(\n",
        "            nn.Conv2d(20, 40, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(40),\n",
        "            nn.ReLU())\n",
        "        self.layer4 = nn.Sequential(\n",
        "            nn.Conv2d(40, 40, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(40),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
        "            )\n",
        "        self.layer5 = nn.Sequential(\n",
        "            nn.Conv2d(40, 40, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(40),\n",
        "            nn.ReLU())\n",
        "        self.layer6 = nn.Sequential(\n",
        "            nn.Conv2d(40, 40, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(40),\n",
        "            nn.ReLU())\n",
        "        self.layer7 = nn.Sequential(\n",
        "            nn.Sequential(\n",
        "            nn.Conv2d(40, 40, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(40),\n",
        "            nn.ReLU()),\n",
        "\n",
        "            nn.Sequential(\n",
        "            nn.Conv2d(40, 40, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(40),\n",
        "            nn.ReLU()),\n",
        "\n",
        "            # nn.Sequential(\n",
        "            # nn.Conv2d(40, 40, kernel_size=3, stride=1, padding=1),\n",
        "            # nn.BatchNorm2d(40),\n",
        "            # nn.ReLU())\n",
        "        )\n",
        "        self.tovect = ToVect()\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(2560, 1000),\n",
        "            nn.ReLU())\n",
        "        self.fc1 = nn.Sequential(\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(1000, 100),\n",
        "            nn.ReLU())\n",
        "        self.fc2= nn.Sequential(\n",
        "            nn.Linear(100, num_classes))\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.layer1(x).to(device)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "        out = self.layer5(out)\n",
        "        out = self.layer6(out)\n",
        "        out = self.layer7(out)\n",
        "        out = self.tovect(out)\n",
        "        out = self.fc(out)\n",
        "        out = self.fc1(out)\n",
        "        out = self.fc2(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "NJTLzIFBdzcr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ks = 3\n",
        "cc = 2\n",
        "\n",
        "class CNN3(nn.Module):#три пулинга\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(CNN3, self).__init__()\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Conv2d(3, 20, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(20),\n",
        "            nn.ReLU())\n",
        "        self.layer2 = nn.Sequential(\n",
        "            nn.Conv2d(20, 20, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(20),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
        "        self.layer3 = nn.Sequential(\n",
        "            nn.Conv2d(20, 40, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(40),\n",
        "            nn.ReLU())\n",
        "        self.layer4 = nn.Sequential(\n",
        "            nn.Conv2d(40, 40, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(40),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
        "            )\n",
        "        self.layer5 = nn.Sequential(\n",
        "            nn.Conv2d(40, 80, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(80),\n",
        "            nn.ReLU())\n",
        "        self.layer6 = nn.Sequential(\n",
        "            nn.Conv2d(80, 80, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(80),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
        "        self.layer7 = nn.Sequential(\n",
        "            nn.Sequential(\n",
        "            nn.Conv2d(80, 80, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(80),\n",
        "            nn.ReLU()),\n",
        "\n",
        "            nn.Sequential(\n",
        "            nn.Conv2d(80, 80, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(80),\n",
        "            nn.ReLU()),\n",
        "\n",
        "            # nn.Sequential(\n",
        "            # nn.Conv2d(40, 40, kernel_size=3, stride=1, padding=1),\n",
        "            # nn.BatchNorm2d(40),\n",
        "            # nn.ReLU())\n",
        "        )\n",
        "        self.tovect = ToVect()\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(1280, 1000),\n",
        "            nn.ReLU())\n",
        "        self.fc1 = nn.Sequential(\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(1000, 100),\n",
        "            nn.ReLU())\n",
        "        self.fc2= nn.Sequential(\n",
        "            nn.Linear(100, num_classes))\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.layer1(x).to(device)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "        out = self.layer5(out)\n",
        "        out = self.layer6(out)\n",
        "        out = self.layer7(out)\n",
        "        out = self.tovect(out)\n",
        "        out = self.fc(out)\n",
        "        out = self.fc1(out)\n",
        "        out = self.fc2(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "e50z4p2Jd1dc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ks = 3\n",
        "cc = 2\n",
        "\n",
        "class CNN4(nn.Module):#четыре пулинга\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(CNN4, self).__init__()\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Conv2d(3, 20, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(20),\n",
        "            nn.ReLU())\n",
        "        self.layer2 = nn.Sequential(\n",
        "            nn.Conv2d(20, 20, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(20),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
        "        self.layer3 = nn.Sequential(\n",
        "            nn.Conv2d(20, 40, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(40),\n",
        "            nn.ReLU())\n",
        "        self.layer4 = nn.Sequential(\n",
        "            nn.Conv2d(40, 40, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(40),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
        "            )\n",
        "        self.layer5 = nn.Sequential(\n",
        "            nn.Conv2d(40, 80, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(80),\n",
        "            nn.ReLU())\n",
        "        self.layer6 = nn.Sequential(\n",
        "            nn.Conv2d(80, 80, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(80),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
        "        self.layer7 = nn.Sequential(\n",
        "            nn.Sequential(\n",
        "            nn.Conv2d(80, 160, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(160),\n",
        "            nn.ReLU()),\n",
        "\n",
        "            nn.Sequential(\n",
        "            nn.Conv2d(160, 160, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(160),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size = 2, stride = 2)),\n",
        "\n",
        "            nn.Sequential(\n",
        "            nn.Conv2d(160, 160, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(160),\n",
        "            nn.ReLU()),\n",
        "\n",
        "            nn.Sequential(\n",
        "            nn.Conv2d(160, 160, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(160),\n",
        "            nn.ReLU())\n",
        "        )\n",
        "        self.tovect = ToVect()\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(640, 500),\n",
        "            nn.ReLU())\n",
        "        self.fc1 = nn.Sequential(\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(500, 100),\n",
        "            nn.ReLU())\n",
        "        self.fc2= nn.Sequential(\n",
        "            nn.Linear(100, num_classes))\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.layer1(x).to(device)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "        out = self.layer5(out)\n",
        "        out = self.layer6(out)\n",
        "        out = self.layer7(out)\n",
        "        out = self.tovect(out)\n",
        "        out = self.fc(out)\n",
        "        out = self.fc1(out)\n",
        "        out = self.fc2(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "EmMLCy5td3lC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ks = 3\n",
        "cc = 2\n",
        "\n",
        "class CNN5(nn.Module):#пять пулингов\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(CNN5, self).__init__()\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Conv2d(3, 20, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(20),\n",
        "            nn.ReLU())\n",
        "        self.layer2 = nn.Sequential(\n",
        "            nn.Conv2d(20, 20, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(20),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
        "        self.layer3 = nn.Sequential(\n",
        "            nn.Conv2d(20, 40, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(40),\n",
        "            nn.ReLU())\n",
        "        self.layer4 = nn.Sequential(\n",
        "            nn.Conv2d(40, 40, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(40),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
        "            )\n",
        "        self.layer5 = nn.Sequential(\n",
        "            nn.Conv2d(40, 80, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(80),\n",
        "            nn.ReLU())\n",
        "        self.layer6 = nn.Sequential(\n",
        "            nn.Conv2d(80, 80, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(80),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
        "        self.layer7 = nn.Sequential(\n",
        "            nn.Sequential(\n",
        "            nn.Conv2d(80, 160, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(160),\n",
        "            nn.ReLU()),\n",
        "\n",
        "            nn.Sequential(\n",
        "            nn.Conv2d(160, 160, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(160),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size = 2, stride = 2)),\n",
        "\n",
        "            nn.Sequential(\n",
        "            nn.Conv2d(160, 320, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(320),\n",
        "            nn.ReLU()),\n",
        "\n",
        "            nn.Sequential(\n",
        "            nn.Conv2d(320, 320, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(320),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size = 2, stride = 2)),\n",
        "\n",
        "            nn.Sequential(\n",
        "            nn.Conv2d(320, 320, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(320),\n",
        "            nn.ReLU()),\n",
        "\n",
        "            nn.Sequential(\n",
        "            nn.Conv2d(320, 320, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(320),\n",
        "            nn.ReLU()),\n",
        "\n",
        "            nn.Sequential(\n",
        "            nn.Conv2d(320, 320, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(320),\n",
        "            nn.ReLU()),\n",
        "            # nn.Sequential(\n",
        "            # nn.Conv2d(320, 320, kernel_size=3, stride=1, padding=1),\n",
        "            # nn.BatchNorm2d(320),\n",
        "            # nn.ReLU())\n",
        "        )\n",
        "        self.tovect = ToVect()\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(320, 300),\n",
        "            nn.ReLU())\n",
        "        self.fc1 = nn.Sequential(\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(300, 300),\n",
        "            nn.ReLU())\n",
        "        self.fc2= nn.Sequential(\n",
        "            nn.Linear(300, num_classes))\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.layer1(x).to(device)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "        out = self.layer5(out)\n",
        "        out = self.layer6(out)\n",
        "        out = self.layer7(out)\n",
        "        out = self.tovect(out)\n",
        "        out = self.fc(out)\n",
        "        out = self.fc1(out)\n",
        "        out = self.fc2(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "x10VMZ0fd5lw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, n_e = 15, l_r = 0.005):\n",
        "  num_classes = 10\n",
        "  num_epochs = n_e\n",
        "  batch_size = 8\n",
        "  learning_rate = l_r\n",
        "\n",
        "  # Loss and optimizer\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, weight_decay = 0.005, momentum = 0.9)\n",
        "\n",
        "\n",
        "  # Train the model\n",
        "  total_step = len(train_loader)\n",
        "\n",
        "  total_step = len(train_loader)\n",
        "\n",
        "  for epoch in range(num_epochs):\n",
        "      for i, (images, labels) in enumerate(train_loader):\n",
        "          # Move tensors to the configured device\n",
        "          images = images.to(device)\n",
        "          labels = labels.to(device)\n",
        "\n",
        "          # Forward pass\n",
        "          outputs = model(images)\n",
        "          loss = criterion(outputs, labels)\n",
        "\n",
        "          # Backward and optimize\n",
        "          optimizer.zero_grad()\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "\n",
        "      print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'\n",
        "                    .format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n",
        "\n",
        "      # Validation\n",
        "      with torch.no_grad():\n",
        "          correct = 0\n",
        "          total = 0\n",
        "          for images, labels in valid_loader:\n",
        "              images = images.to(device)\n",
        "              labels = labels.to(device)\n",
        "              outputs = model(images)\n",
        "              _, predicted = torch.max(outputs.data, 1)\n",
        "              total += labels.size(0)\n",
        "              correct += (predicted == labels).sum().item()\n",
        "              del images, labels, outputs\n",
        "          print(total, correct)\n",
        "          print('Accuracy of the network on the {} validation images: {} %'.format(total, 100 * correct / total))"
      ],
      "metadata": {
        "id": "IbKbOn9qd8tr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def check(model):\n",
        "  with torch.no_grad():\n",
        "      correct = 0\n",
        "      total = 0\n",
        "      for images, labels in test_loader:\n",
        "          images = images.to(device)\n",
        "          labels = labels.to(device)\n",
        "          outputs = model(images)\n",
        "          _, predicted = torch.max(outputs.data, 1)\n",
        "          total += labels.size(0)\n",
        "          correct += (predicted == labels).sum().item()\n",
        "          del images, labels, outputs\n",
        "\n",
        "      print('Accuracy of the network on the {} test images: {} %'.format(total, 100 * correct / total))"
      ],
      "metadata": {
        "id": "iG6hg9kEeC4_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model1 = CNN().to(device)\n",
        "model2 = CNN2().to(device)\n",
        "model3 = CNN3().to(device)\n",
        "model4 = CNN4().to(device)\n",
        "model5 = CNN5().to(device)"
      ],
      "metadata": {
        "id": "y7kzN0RCeFg4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train(model1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "11g6n-kBeH7W",
        "outputId": "2fe32ac3-897f-4e70-a4d0-86da57222e98"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/20], Step [5625/5625], Loss: 0.9653\n",
            "5000 2238\n",
            "Accuracy of the network on the 5000 validation images: 44.76 %\n",
            "Epoch [2/20], Step [5625/5625], Loss: 1.4146\n",
            "5000 2607\n",
            "Accuracy of the network on the 5000 validation images: 52.14 %\n",
            "Epoch [3/20], Step [5625/5625], Loss: 1.4810\n",
            "5000 2881\n",
            "Accuracy of the network on the 5000 validation images: 57.62 %\n",
            "Epoch [4/20], Step [5625/5625], Loss: 1.0128\n",
            "5000 2986\n",
            "Accuracy of the network on the 5000 validation images: 59.72 %\n",
            "Epoch [5/20], Step [5625/5625], Loss: 0.6591\n",
            "5000 2847\n",
            "Accuracy of the network on the 5000 validation images: 56.94 %\n",
            "Epoch [6/20], Step [5625/5625], Loss: 0.6213\n",
            "5000 2723\n",
            "Accuracy of the network on the 5000 validation images: 54.46 %\n",
            "Epoch [7/20], Step [5625/5625], Loss: 1.1089\n",
            "5000 2963\n",
            "Accuracy of the network on the 5000 validation images: 59.26 %\n",
            "Epoch [8/20], Step [5625/5625], Loss: 1.5392\n",
            "5000 3046\n",
            "Accuracy of the network on the 5000 validation images: 60.92 %\n",
            "Epoch [9/20], Step [5625/5625], Loss: 0.8504\n",
            "5000 2919\n",
            "Accuracy of the network on the 5000 validation images: 58.38 %\n",
            "Epoch [10/20], Step [5625/5625], Loss: 0.9515\n",
            "5000 3103\n",
            "Accuracy of the network on the 5000 validation images: 62.06 %\n",
            "Epoch [11/20], Step [5625/5625], Loss: 1.0759\n",
            "5000 3021\n",
            "Accuracy of the network on the 5000 validation images: 60.42 %\n",
            "Epoch [12/20], Step [5625/5625], Loss: 1.5380\n",
            "5000 3007\n",
            "Accuracy of the network on the 5000 validation images: 60.14 %\n",
            "Epoch [13/20], Step [5625/5625], Loss: 1.2339\n",
            "5000 3115\n",
            "Accuracy of the network on the 5000 validation images: 62.3 %\n",
            "Epoch [14/20], Step [5625/5625], Loss: 0.9866\n",
            "5000 3136\n",
            "Accuracy of the network on the 5000 validation images: 62.72 %\n",
            "Epoch [15/20], Step [5625/5625], Loss: 1.3160\n",
            "5000 3124\n",
            "Accuracy of the network on the 5000 validation images: 62.48 %\n",
            "Epoch [16/20], Step [5625/5625], Loss: 1.8171\n",
            "5000 2987\n",
            "Accuracy of the network on the 5000 validation images: 59.74 %\n",
            "Epoch [17/20], Step [5625/5625], Loss: 0.4529\n",
            "5000 3150\n",
            "Accuracy of the network on the 5000 validation images: 63.0 %\n",
            "Epoch [18/20], Step [5625/5625], Loss: 0.6884\n",
            "5000 3096\n",
            "Accuracy of the network on the 5000 validation images: 61.92 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "check(model1)"
      ],
      "metadata": {
        "id": "4b1rEdxseIy6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train(model2)"
      ],
      "metadata": {
        "id": "cZZr3taOeVwj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "check(model2)"
      ],
      "metadata": {
        "id": "P_uVe8QfeXeC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train(model3)"
      ],
      "metadata": {
        "id": "nBaBIK9yeai6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "check(model3)"
      ],
      "metadata": {
        "id": "8VZVtoRjecyr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train(model4)"
      ],
      "metadata": {
        "id": "1hXwfHgheesV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "check(model4)"
      ],
      "metadata": {
        "id": "NIN0_penehJn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train(model5)"
      ],
      "metadata": {
        "id": "4P3shZ9Pejve"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "check(model5)"
      ],
      "metadata": {
        "id": "aHawA1Rgelu2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Так как лучше всего себя показал 3-й вариант, улучшим именно его, увеличив количество слоев изображения после свертки"
      ],
      "metadata": {
        "id": "L2cwiGWHk5os"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TheBestOneIHope(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(TheBestOneIHope, self).__init__()\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Conv2d(3, 32 * 2, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(32 * 2),\n",
        "            nn.ReLU())\n",
        "        self.layer2 = nn.Sequential(\n",
        "            nn.Conv2d(32 * 2, 32 * 2, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(32 * 2),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
        "        self.layer3 = nn.Sequential(\n",
        "            nn.Conv2d(32 * 2, 64 * 2, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(64 * 2),\n",
        "            nn.ReLU())\n",
        "        self.layer4 = nn.Sequential(\n",
        "            nn.Conv2d(64 * 2, 64 * 2, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(64 * 2),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
        "            )\n",
        "        self.layer5 = nn.Sequential(\n",
        "            nn.Conv2d(64 * 2, 128 * 2, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(128 * 2),\n",
        "            nn.ReLU())\n",
        "        self.layer6 = nn.Sequential(\n",
        "            nn.Conv2d(128 * 2, 128 * 2, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(128 * 2),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
        "        self.layer7 = nn.Sequential(\n",
        "            nn.Sequential(\n",
        "            nn.Conv2d(128 * 2, 128 * 2, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(128 * 2),\n",
        "            nn.ReLU()),\n",
        "\n",
        "            nn.Sequential(\n",
        "            nn.Conv2d(128 * 2, 128 * 2, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(128 * 2),\n",
        "            nn.ReLU()),\n",
        "\n",
        "        )\n",
        "        self.tovect = ToVect()\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(4*4*128 * 2, 1000),\n",
        "            nn.ReLU())\n",
        "        self.fc1 = nn.Sequential(\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(1000, 100),\n",
        "            nn.ReLU())\n",
        "        self.fc2= nn.Sequential(\n",
        "            nn.Linear(100, num_classes))\n",
        "\n",
        "    def forward(self, x):\n",
        "        # out = self.layer0(x).to(device)\n",
        "        out = self.layer1(x)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "        out = self.layer5(out)\n",
        "        out = self.layer6(out)\n",
        "        out = self.layer7(out)\n",
        "        out = self.tovect(out)\n",
        "        out = self.fc(out)\n",
        "        out = self.fc1(out)\n",
        "        out = self.fc2(out)\n",
        "        return out\n",
        "\n",
        "best_model = TheBestOneIHope().to(device)"
      ],
      "metadata": {
        "id": "bTFEys7Qen9g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train(best_model, 15, 0.01)\n",
        "train(best_model, 15)\n",
        "train(best_model, 15, 0.001)\n",
        "train(best_model, 15, 0.0005)\n",
        "train(best_model, 15, 0.00005)"
      ],
      "metadata": {
        "id": "IN37vpWoe_cf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "check(best_model)"
      ],
      "metadata": {
        "id": "iQCjP0TJfCZr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}